"""
GraphRAG ì±—ë´‡ ì„œë²„
- ChromaDB ë²¡í„° ê²€ìƒ‰
- BGE-M3 Re-ranking (ColBERT)
- Ollama LLM ë‹µë³€ ìƒì„±
"""

import os
import sys
import json
import warnings
import ssl
import urllib3

# SSL ìš°íšŒ ì„¤ì •
os.environ['HF_HUB_DISABLE_SSL_VERIFY'] = '1'
os.environ['CURL_CA_BUNDLE'] = ''
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

from flask import Flask, render_template, request, jsonify
import chromadb
from sentence_transformers import SentenceTransformer
import requests

# ì„¤ì •
CHROMA_PATH = "chroma_db_fulltext"  # ì›ë³¸ TXT íŒŒì¼ ì„ë² ë”©
COLLECTION_NAME = "dtro_fulltext_v1"
MODEL_NAME = "BAAI/bge-m3"
OLLAMA_MODEL = "hf.co/unsloth/gemma-3n-E4B-it-GGUF:Q4_K_M"  # ê¸°ë³¸ ëª¨ë¸
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_URL = f"{OLLAMA_BASE_URL}/api/generate"
OLLAMA_TAGS_URL = f"{OLLAMA_BASE_URL}/api/tags"

# í˜„ì¬ ì„ íƒëœ ëª¨ë¸ (ë™ì  ë³€ê²½ ê°€ëŠ¥)
current_model = OLLAMA_MODEL

# ë””í´íŠ¸ í”„ë¡¬í”„íŠ¸ (ìµœì í™”ëœ ê¸°ë³¸ê°’)
DEFAULT_PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ ëŒ€êµ¬êµí†µê³µì‚¬ì˜ ê·œì • ë° ë‚´ê·œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™:**
1. ì œê³µëœ ë¬¸ì„œì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”
3. ìˆ«ìë‚˜ ê¸°ê°„ ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°, ë‹¨ê³„ë³„ë¡œ ê³„ì‚° ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”
   ì˜ˆ: "9ê¸‰â†’8ê¸‰: 1ë…„, 8ê¸‰â†’7ê¸‰: 1ë…„, 7ê¸‰â†’6ê¸‰: 1ë…„ 6ê°œì›” â†’ ì´ 3ë…„ 6ê°œì›”"
4. ê´€ë ¨ ê·œì •ì´ë‚˜ ì¡°í•­ì„ ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”

**ë‹µë³€ í˜•ì‹:**
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë‹µë³€
- í•„ìš”ì‹œ ë²ˆí˜¸ ë§¤ê¸°ê¸°ë‚˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‚¬ìš©
- ì¶œì²˜ ë¬¸ì„œëª… ëª…ì‹œ

**ì°¸ê³  ë¬¸ì„œ:**
{context}

**ì‚¬ìš©ì ì§ˆë¬¸:**
{query}

**ë‹µë³€:**"""

# í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í”„ë¡¬í”„íŠ¸ (ë™ì  ë³€ê²½ ê°€ëŠ¥)
current_prompt_template = DEFAULT_PROMPT_TEMPLATE

# Re-ranking ì„¤ì •
ENABLE_RERANK = True
TOP_K = 20  # 1ì°¨ ê²€ìƒ‰
RERANK_TOP_K = 5  # 2ì°¨ ë°˜í™˜

app = Flask(__name__)

print("="*60)
print("ğŸš€ GraphRAG ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
print("="*60)

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print(f"ğŸ“¦ ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {MODEL_NAME}")
try:
    embedding_model = SentenceTransformer(MODEL_NAME)
    embedding_model.max_seq_length = 8192
    print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì°¨ì›: {embedding_model.get_sentence_embedding_dimension()})")
except Exception as e:
    print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    sys.exit(1)

# Re-ranker ì´ˆê¸°í™”
reranker = None
if ENABLE_RERANK:
    print("ğŸ”„ Re-ranker ì´ˆê¸°í™” ì¤‘...")
    try:
        from FlagEmbedding import BGEM3FlagModel
        reranker = BGEM3FlagModel(MODEL_NAME, use_fp16=True)
        print("âœ… Re-ranker ë¡œë“œ ì™„ë£Œ (ColBERT ëª¨ë“œ)")
    except ImportError:
        print("âš ï¸  FlagEmbedding ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ìœ ì‚¬ë„ Re-ranking ì‚¬ìš©")
        reranker = embedding_model
    except Exception as e:
        print(f"âš ï¸  Re-ranker ë¡œë”© ì‹¤íŒ¨: {e} - Re-ranking ë¹„í™œì„±í™”")
        ENABLE_RERANK = False

# ChromaDB ì—°ê²°
print(f"ğŸ’¾ ChromaDB ì—°ê²° ì¤‘: {CHROMA_PATH}")
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)
    collection = chroma_client.get_collection(name=COLLECTION_NAME)
    doc_count = collection.count()
    print(f"âœ… ChromaDB ì—°ê²° ì„±ê³µ (ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ)")
except Exception as e:
    print(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
    sys.exit(1)

# Ollama ì—°ê²° í™•ì¸
print(f"ğŸ¤– Ollama ì—°ê²° í™•ì¸: {OLLAMA_MODEL}")
try:
    test_response = requests.post(
        OLLAMA_URL,
        json={
            "model": OLLAMA_MODEL,
            "prompt": "í…ŒìŠ¤íŠ¸",
            "stream": False
        },
        timeout=10
    )
    if test_response.status_code == 200:
        print("âœ… Ollama ì—°ê²° ì„±ê³µ")
    else:
        print(f"âš ï¸  Ollama ì‘ë‹µ ì´ìƒ: {test_response.status_code}")
except Exception as e:
    print(f"âš ï¸  Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
    print("   (ì±—ë´‡ì€ ì‹¤í–‰ë˜ì§€ë§Œ ë‹µë³€ ìƒì„± ë¶ˆê°€)")


# ==========================================
# RAG ê²€ìƒ‰ í•¨ìˆ˜
# ==========================================

def search_chromadb(query: str, top_k: int = TOP_K):
    """ChromaDBì—ì„œ ë²¡í„° ê²€ìƒ‰"""
    try:
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = embedding_model.encode(query, normalize_embeddings=True)
        
        # ê²€ìƒ‰
        results = collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k
        )
        
        # ê²°ê³¼ íŒŒì‹±
        documents = []
        if results['documents'] and len(results['documents']) > 0:
            for i in range(len(results['documents'][0])):
                doc = {
                    'id': results['ids'][0][i],
                    'text': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if 'distances' in results else 0.0
                }
                documents.append(doc)
        
        return documents
    
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


def rerank_results(query: str, documents: list, top_k: int = RERANK_TOP_K):
    """Re-rankingìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬"""
    if not ENABLE_RERANK or not reranker or len(documents) == 0:
        return documents[:top_k]
    
    try:
        # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        doc_texts = [doc['text'] for doc in documents]
        
        # Re-ranking
        if hasattr(reranker, 'compute_score'):
            # FlagEmbedding (ColBERT)
            sentence_pairs = [[query, text] for text in doc_texts]
            scores = reranker.compute_score(
                sentence_pairs,
                weights_for_different_modes=[0.0, 0.0, 1.0]  # ColBERTë§Œ ì‚¬ìš©
            )
            
            # ì ìˆ˜ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(scores, dict):
                scores = scores.get('colbert', [0] * len(doc_texts))
        else:
            # SentenceTransformer (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            query_emb = reranker.encode(query, normalize_embeddings=True)
            doc_embs = reranker.encode(doc_texts, normalize_embeddings=True)
            scores = [float(query_emb @ doc_emb) for doc_emb in doc_embs]
        
        # ì ìˆ˜ ì¶”ê°€ ë° ì •ë ¬
        for i, doc in enumerate(documents):
            doc['rerank_score'] = float(scores[i]) if i < len(scores) else 0.0
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        documents.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        return documents[:top_k]
    
    except Exception as e:
        print(f"âš ï¸  Re-ranking ì‹¤íŒ¨: {e} - ì›ë³¸ ìˆœì„œ ë°˜í™˜")
        return documents[:top_k]


def generate_answer_ollama(query: str, context_docs: list):
    """Ollamaë¡œ ë‹µë³€ ìƒì„±"""
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    for i, doc in enumerate(context_docs, 1):
        meta = doc['metadata']
        context_parts.append(f"""
[ë¬¸ì„œ {i}]
ì¹´í…Œê³ ë¦¬: {meta.get('category', 'N/A')} > {meta.get('group', 'N/A')}
ë¬¸ì„œëª…: {meta.get('source_file', 'N/A')}
íƒ€ì…: {meta.get('type', 'N/A')}
ë‚´ìš©:
{doc['text']}
""")
    
    context = "\n".join(context_parts)
    
    # ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
    prompt = current_prompt_template.format(context=context, query=query)

    try:
        # Ollama API í˜¸ì¶œ
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": current_model,  # ë™ì ìœ¼ë¡œ ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "top_p": 0.9,
                    "num_predict": 1024
                }
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            answer = result.get('response', 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨')
            return answer.strip()
        else:
            return f"âŒ Ollama ì‘ë‹µ ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
    
    except requests.exceptions.Timeout:
        return "â±ï¸ ë‹µë³€ ìƒì„± ì‹œê°„ ì´ˆê³¼ (60ì´ˆ)"
    except Exception as e:
        return f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}"


# ==========================================
# Flask ë¼ìš°íŠ¸
# ==========================================

@app.route('/')
def index():
    return render_template('index_graphrag.html')


@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        query = data.get('message', '').strip()
        
        if not query:
            return jsonify({'error': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400
        
        # 1ë‹¨ê³„: ChromaDB ê²€ìƒ‰
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        documents = search_chromadb(query, top_k=TOP_K)
        print(f"   ğŸ“Š 1ì°¨ ê²€ìƒ‰: {len(documents)}ê°œ ë°œê²¬")
        
        if not documents:
            return jsonify({
                'answer': 'ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.',
                'sources': []
            })
        
        # 2ë‹¨ê³„: Re-ranking
        if ENABLE_RERANK:
            documents = rerank_results(query, documents, top_k=RERANK_TOP_K)
            print(f"   ğŸ”„ Re-ranking: ìƒìœ„ {len(documents)}ê°œ ì„ íƒ")
        else:
            documents = documents[:RERANK_TOP_K]
        
        # 3ë‹¨ê³„: ë‹µë³€ ìƒì„±
        print(f"   ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...")
        answer = generate_answer_ollama(query, documents)
        
        # ì¶œì²˜ ì •ë³´ êµ¬ì„±
        sources = []
        for i, doc in enumerate(documents, 1):
            meta = doc['metadata']
            source = {
                'index': i,
                'category': f"{meta.get('category', 'N/A')} > {meta.get('group', 'N/A')}",
                'file': meta.get('source_file', 'N/A'),
                'type': meta.get('type', 'N/A'),
                'label': meta.get('label', 'N/A'),
                'score': doc.get('rerank_score', doc.get('distance', 0.0))
            }
            sources.append(source)
        
        print(f"   âœ… ë‹µë³€ ì™„ë£Œ\n")
        
        return jsonify({
            'answer': answer,
            'sources': sources
        })
    
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return jsonify({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}), 500


@app.route('/health', methods=['GET'])
def health():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'ok',
        'model': current_model,
        'documents': collection.count(),
        'reranking': ENABLE_RERANK
    })


@app.route('/models', methods=['GET'])
def get_models():
    """Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(OLLAMA_TAGS_URL, timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = []
            for model in data.get('models', []):
                models.append({
                    'name': model.get('name', ''),
                    'size': model.get('size', 0),
                    'modified': model.get('modified_at', '')
                })
            return jsonify({
                'models': models,
                'current': current_model
            })
        else:
            return jsonify({'error': 'Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜'}), 500
    except Exception as e:
        return jsonify({'error': f'ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'}), 500


@app.route('/models/select', methods=['POST'])
def select_model():
    """ì‚¬ìš©í•  Ollama ëª¨ë¸ ë³€ê²½"""
    global current_model
    try:
        data = request.json
        model_name = data.get('model', '').strip()
        
        if not model_name:
            return jsonify({'error': 'ëª¨ë¸ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # ëª¨ë¸ í…ŒìŠ¤íŠ¸
        test_response = requests.post(
            OLLAMA_URL,
            json={
                "model": model_name,
                "prompt": "í…ŒìŠ¤íŠ¸",
                "stream": False
            },
            timeout=10
        )
        
        if test_response.status_code == 200:
            current_model = model_name
            print(f"âœ… ëª¨ë¸ ë³€ê²½: {current_model}")
            return jsonify({
                'success': True,
                'model': current_model
            })
        else:
            return jsonify({'error': f'ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ìƒíƒœ: {test_response.status_code})'}), 500
    
    except Exception as e:
        return jsonify({'error': f'ëª¨ë¸ ë³€ê²½ ì‹¤íŒ¨: {str(e)}'}), 500


@app.route('/prompt', methods=['GET'])
def get_prompt():
    """í˜„ì¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¡°íšŒ"""
    return jsonify({
        'current': current_prompt_template,
        'default': DEFAULT_PROMPT_TEMPLATE
    })


@app.route('/prompt/update', methods=['POST'])
def update_prompt():
    """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³€ê²½"""
    global current_prompt_template
    try:
        data = request.json
        new_prompt = data.get('prompt', '').strip()
        
        if not new_prompt:
            return jsonify({'error': 'í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤'}), 400
        
        # {context}ì™€ {query} í”Œë ˆì´ìŠ¤í™€ë” í™•ì¸
        if '{context}' not in new_prompt or '{query}' not in new_prompt:
            return jsonify({'error': 'í”„ë¡¬í”„íŠ¸ì— {context}ì™€ {query} í”Œë ˆì´ìŠ¤í™€ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        current_prompt_template = new_prompt
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì™„ë£Œ")
        
        return jsonify({
            'success': True,
            'prompt': current_prompt_template
        })
    
    except Exception as e:
        return jsonify({'error': f'í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì‹¤íŒ¨: {str(e)}'}), 500


@app.route('/prompt/reset', methods=['POST'])
def reset_prompt():
    """í”„ë¡¬í”„íŠ¸ë¥¼ ë””í´íŠ¸ë¡œ ì´ˆê¸°í™”"""
    global current_prompt_template
    current_prompt_template = DEFAULT_PROMPT_TEMPLATE
    print(f"âœ… í”„ë¡¬í”„íŠ¸ ë””í´íŠ¸ë¡œ ì´ˆê¸°í™”")
    
    return jsonify({
        'success': True,
        'prompt': current_prompt_template
    })


# ==========================================
# ì‹¤í–‰
# ==========================================
if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸ‰ GraphRAG ì±—ë´‡ ì„œë²„ ì‹œì‘")
    print("="*60)
    print(f"ğŸ“ URL: http://localhost:5000")
    print(f"ğŸ¤– LLM: {OLLAMA_MODEL}")
    print(f"ğŸ“š ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ")
    print(f"ğŸ”„ Re-ranking: {'í™œì„±í™”' if ENABLE_RERANK else 'ë¹„í™œì„±í™”'}")
    print("="*60 + "\n")
    
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)
